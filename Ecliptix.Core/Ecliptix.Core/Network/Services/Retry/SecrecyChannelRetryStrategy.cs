using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Diagnostics.CodeAnalysis;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Polly;
using Polly.Contrib.WaitAndRetry;
using Polly.Wrap;
using Ecliptix.Core.AppEvents.Network;
using Ecliptix.Core.Network.Contracts.Services;
using Ecliptix.Core.Network.Core.Providers;
using Ecliptix.Utilities;
using Ecliptix.Utilities.Failures.Network;
using Serilog;

namespace Ecliptix.Core.Network.Services.Retry;

/// <summary>
/// AOT-compatible, thread-safe, production-ready retry strategy implementation.
/// Addresses all critical issues: reflection removal, thread safety, memory leaks,
/// state consistency, UI decoupling, error handling, and resource management.
/// </summary>
public sealed class SecrecyChannelRetryStrategy : IRetryStrategy, IDisposable
{
    #region Private Fields

    private readonly ImprovedRetryConfiguration _configuration;
    private readonly INetworkEvents _networkEvents;
    private readonly IUiDispatcher _uiDispatcher;
    private readonly ConcurrentDictionary<string, RetryOperationInfo> _activeRetryOperations = new();
    private readonly SemaphoreSlim _stateLock = new(1, 1);
    private readonly Timer _cleanupTimer;
    private readonly IDisposable? _manualRetrySubscription;

    private Lazy<NetworkProvider>? _lazyNetworkProvider;
    private volatile bool _isDisposed;
    private const int MAX_TRACKED_OPERATIONS = 1000;
    private const int CLEANUP_INTERVAL_MINUTES = 5;
    private const int OPERATION_TIMEOUT_MINUTES = 10;

    #endregion

    #region Private Classes

    private sealed class RetryOperationInfo
    {
        public required string OperationName { get; init; }
        public required uint ConnectId { get; init; }
        public required DateTime StartTime { get; init; }
        public required int MaxRetries { get; init; }
        public required string UniqueKey { get; init; }
        
        // Thread-safe fields with Interlocked operations
        private int _currentRetryCount;
        private int _isExhausted;
        
        public int CurrentRetryCount 
        { 
            get => _currentRetryCount; 
            set => Interlocked.Exchange(ref _currentRetryCount, value); 
        }
        
        public bool IsExhausted 
        { 
            get => _isExhausted == 1; 
            set => Interlocked.Exchange(ref _isExhausted, value ? 1 : 0); 
        }

        public Func<Task<Result<object, NetworkFailure>>>? Operation { get; init; }
    }

    #endregion

    #region Constructor

    public SecrecyChannelRetryStrategy(
        ImprovedRetryConfiguration configuration,
        INetworkEvents networkEvents,
        IUiDispatcher uiDispatcher)
    {
        ArgumentNullException.ThrowIfNull(configuration);
        ArgumentNullException.ThrowIfNull(networkEvents);
        ArgumentNullException.ThrowIfNull(uiDispatcher);

        // Validate configuration on construction
        configuration.ValidateAndThrow();

        _configuration = configuration;
        _networkEvents = networkEvents;
        _uiDispatcher = uiDispatcher;

        // Setup cleanup timer to prevent memory leaks
        _cleanupTimer = new Timer(
            CleanupAbandonedOperations, 
            null, 
            TimeSpan.FromMinutes(CLEANUP_INTERVAL_MINUTES),
            TimeSpan.FromMinutes(CLEANUP_INTERVAL_MINUTES));

        // Subscribe to manual retry events with proper disposal
        try
        {
            _manualRetrySubscription = _networkEvents.ManualRetryRequested
                .Subscribe(evt => _ = HandleManualRetryRequestAsync(evt));
        }
        catch (Exception ex)
        {
            Log.Error(ex, "Failed to subscribe to manual retry events");
            Dispose();
            throw;
        }

        Log.Information("SecrecyChannelRetryStrategy initialized with configuration: MaxRetries={MaxRetries}, InitialDelay={InitialDelay}", 
            _configuration.MaxRetries, _configuration.InitialRetryDelay);
    }

    #endregion

    #region Public Methods

    public void SetLazyNetworkProvider(Lazy<NetworkProvider> lazyNetworkProvider)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        _lazyNetworkProvider = lazyNetworkProvider;
    }

    public async Task<Result<TResponse, NetworkFailure>> ExecuteSecrecyChannelOperationAsync<TResponse>(
        Func<Task<Result<TResponse, NetworkFailure>>> operation,
        string operationName,
        uint? connectId = null,
        int? maxRetries = null,
        CancellationToken cancellationToken = default)
    {
        return await ExecuteSecrecyChannelOperationInternalAsync(
            operation, operationName, connectId, maxRetries, cancellationToken, bypassExhaustionCheck: false);
    }

    public async Task<Result<TResponse, NetworkFailure>> ExecuteManualRetryOperationAsync<TResponse>(
        Func<Task<Result<TResponse, NetworkFailure>>> operation,
        string operationName,
        uint? connectId = null,
        int? maxRetries = null,
        CancellationToken cancellationToken = default)
    {
        Log.Information("ðŸ”„ MANUAL RETRY: Executing operation '{OperationName}' bypassing exhaustion checks", operationName);
        return await ExecuteSecrecyChannelOperationInternalAsync(
            operation, operationName, connectId, maxRetries, cancellationToken, bypassExhaustionCheck: true);
    }

    private async Task<Result<TResponse, NetworkFailure>> ExecuteSecrecyChannelOperationInternalAsync<TResponse>(
        Func<Task<Result<TResponse, NetworkFailure>>> operation,
        string operationName,
        uint? connectId,
        int? maxRetries,
        CancellationToken cancellationToken,
        bool bypassExhaustionCheck)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        ArgumentNullException.ThrowIfNull(operation);
        ArgumentException.ThrowIfNullOrWhiteSpace(operationName);

        if (!connectId.HasValue)
        {
            return Result<TResponse, NetworkFailure>.Err(
                NetworkFailure.InvalidRequestType("Connection ID is required"));
        }

        // Use configuration value if maxRetries not specified
        int actualMaxRetries = maxRetries ?? _configuration.MaxRetries;

        // Thread-safe global exhaustion check (skip for manual retries)
        if (!bypassExhaustionCheck && await IsGloballyExhaustedAsync())
        {
            Log.Information("ðŸš« OPERATION BLOCKED: Cannot start new operation '{OperationName}' - system is globally exhausted, manual retry required", operationName);
            return Result<TResponse, NetworkFailure>.Err(
                NetworkFailure.DataCenterNotResponding("All operations exhausted, manual retry required"));
        }

        Log.Information("ðŸš€ EXECUTE OPERATION: Starting operation '{OperationName}' on ConnectId {ConnectId}", 
            operationName, connectId.Value);

        // Create operation tracking
        DateTime operationStartTime = DateTime.UtcNow;
        string operationKey = CreateOperationKey(operationName, connectId.Value, operationStartTime);

        try
        {
            // Create AOT-compatible typed retry policy
            var retryPolicy = CreateTypedRetryPolicy<TResponse>(actualMaxRetries, operationKey, operationName, connectId.Value);

            // Create context for Polly
            var context = new Context(operationName);

            // Execute with full error handling
            var result = await retryPolicy.ExecuteAsync(
                async (ctx, ct) => {
                    ct.ThrowIfCancellationRequested();
                    var opResult = await operation().ConfigureAwait(false);
                    Log.Debug("ðŸ”§ RETRY POLICY: Operation '{OperationName}' returned IsOk: {IsOk}", 
                        operationName, opResult.IsOk);
                    return opResult;
                },
                context,
                cancellationToken).ConfigureAwait(false);

            // Clean up tracking
            if (result.IsOk)
            {
                StopTrackingOperation(operationKey, "Completed successfully");
            }
            else
            {
                Log.Warning("ðŸ”´ OPERATION FAILED: Operation {OperationName} failed after all retries with error: {Error}", 
                    operationName, result.UnwrapErr().Message);
                
                // Keep exhausted operations tracked for global exhaustion detection
                // They will be cleaned up on manual retry or connection restore
                Log.Debug("ðŸ”´ KEEPING EXHAUSTED: Keeping operation {OperationName} tracked for retry button detection", operationName);
            }

            return result;
        }
        catch (OperationCanceledException) when (cancellationToken.IsCancellationRequested)
        {
            StopTrackingOperation(operationKey, "Operation cancelled");
            return Result<TResponse, NetworkFailure>.Err(
                NetworkFailure.DataCenterNotResponding("Operation cancelled"));
        }
        catch (Exception ex)
        {
            Log.Error(ex, "ðŸš¨ UNEXPECTED ERROR: Operation {OperationName} failed with unexpected exception", operationName);
            StopTrackingOperation(operationKey, $"Unexpected error: {ex.Message}");
            return Result<TResponse, NetworkFailure>.Err(
                NetworkFailure.DataCenterNotResponding($"Unexpected error: {ex.Message}"));
        }
    }

    public async Task<Result<TResponse, NetworkFailure>> ExecuteSecrecyChannelOperationAsync<TResponse>(
        Func<Task<Result<TResponse, NetworkFailure>>> operation,
        string operationName,
        uint? connectId,
        IReadOnlyList<TimeSpan> backoffSchedule,
        bool useJitter = true,
        double jitterRatio = 0.25,
        CancellationToken cancellationToken = default)
    {
        return await ExecuteSecrecyChannelOperationAsync(
            operation,
            operationName,
            connectId,
            backoffSchedule.Count,
            cancellationToken);
    }

    public void ResetConnectionState(uint? connectId = null)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        try
        {
            if (connectId.HasValue)
            {
                var networkProvider = GetNetworkProvider();
                networkProvider?.ClearConnection(connectId.Value);
            }
        }
        catch (Exception ex)
        {
            Log.Warning(ex, "Failed to reset connection state for ConnectId {ConnectId}", connectId);
        }
    }

    public RetryMetrics GetRetryMetrics(uint? connectId = null)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        // For now, return empty metrics - this could be enhanced later
        return new RetryMetrics(0, 0, 0, TimeSpan.Zero, DateTime.MinValue, DateTime.MinValue);
    }

    public ConnectionRetryState? GetConnectionState(uint connectId)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        try
        {
            bool isHealthy = GetNetworkProvider()?.IsConnectionHealthy(connectId) ?? false;
            return new ConnectionRetryState(
                connectId,
                0,
                DateTime.MinValue,
                null,
                !isHealthy,
                !isHealthy ? DateTime.UtcNow : null);
        }
        catch (Exception ex)
        {
            Log.Warning(ex, "Failed to get connection state for ConnectId {ConnectId}", connectId);
            return null;
        }
    }

    public void MarkConnectionHealthy(uint connectId)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        _ = Task.Run(async () =>
        {
            try
            {
                await _stateLock.WaitAsync();
                try
                {
                    var exhaustedOperations = _activeRetryOperations.Values
                        .Where(op => op.ConnectId == connectId && op.IsExhausted)
                        .ToList();

                    foreach (var operation in exhaustedOperations)
                    {
                        operation.IsExhausted = false;
                        operation.CurrentRetryCount = 0;
                        Log.Information("ðŸ”„ CONNECTION HEALTHY: Marking operation {OperationName} as healthy for ConnectId {ConnectId}",
                            operation.OperationName, connectId);
                        
                        // Clean up the operation from tracking since connection is healthy
                        StopTrackingOperation(operation.UniqueKey, "Connection restored");
                    }

                    if (exhaustedOperations.Any())
                    {
                        Log.Information("ðŸ”„ CONNECTION HEALTHY: Reset exhaustion state for ConnectId {ConnectId}, cleaned up {Count} operations", 
                            connectId, exhaustedOperations.Count);
                    }
                }
                finally
                {
                    _stateLock.Release();
                }
            }
            catch (Exception ex)
            {
                Log.Error(ex, "Failed to mark connection healthy for ConnectId {ConnectId}", connectId);
            }
        });
    }

    public bool IsConnectionHealthy(uint connectId)
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        try
        {
            return GetNetworkProvider()?.IsConnectionHealthy(connectId) ?? false;
        }
        catch (Exception ex)
        {
            Log.Warning(ex, "Failed to check connection health for ConnectId {ConnectId}", connectId);
            return false;
        }
    }

    public bool HasExhaustedOperations()
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        try
        {
            return _activeRetryOperations.Values.Any(op => op.IsExhausted);
        }
        catch (Exception ex)
        {
            Log.Warning(ex, "Failed to check for exhausted operations");
            return false;
        }
    }

    public void ClearExhaustedOperations()
    {
        if (_isDisposed) throw new ObjectDisposedException(nameof(SecrecyChannelRetryStrategy));
        
        try
        {
            var exhaustedKeys = _activeRetryOperations.Values
                .Where(op => op.IsExhausted)
                .Select(op => op.UniqueKey)
                .ToList();

            foreach (string key in exhaustedKeys)
            {
                if (_activeRetryOperations.TryRemove(key, out var operation))
                {
                    Log.Debug("ðŸ”„ CLEARED: Removed exhausted operation {OperationName} for fresh retry", operation.OperationName);
                }
            }

            if (exhaustedKeys.Any())
            {
                Log.Information("ðŸ”„ CLEARED: Removed {Count} exhausted operations to allow fresh retry", exhaustedKeys.Count);
            }
        }
        catch (Exception ex)
        {
            Log.Error(ex, "Failed to clear exhausted operations");
        }
    }

    public void Dispose()
    {
        if (_isDisposed)
            return;

        _isDisposed = true;

        try
        {
            _manualRetrySubscription?.Dispose();
            _cleanupTimer?.Dispose();
            _stateLock?.Dispose();
            
            Log.Information("SecrecyChannelRetryStrategy disposed successfully");
        }
        catch (Exception ex)
        {
            Log.Error(ex, "Error during SecrecyChannelRetryStrategy disposal");
        }
    }

    #endregion

    #region Private Methods - Thread-Safe Operations

    private async Task<bool> IsGloballyExhaustedAsync()
    {
        if (_activeRetryOperations.IsEmpty)
            return false;

        await _stateLock.WaitAsync();
        try
        {
            return _activeRetryOperations.Values.All(op => op.IsExhausted);
        }
        finally
        {
            _stateLock.Release();
        }
    }

    private bool IsGloballyExhausted()
    {
        if (_activeRetryOperations.IsEmpty)
            return false;

        // Non-blocking check - may be slightly less accurate but acceptable for onRetry callback
        return _activeRetryOperations.Values.All(op => op.IsExhausted);
    }

    private async Task HandleManualRetryRequestAsync(ManualRetryRequestedEvent evt)
    {
        if (_isDisposed)
            return;

        Log.Information("ðŸ”„ MANUAL RETRY REQUEST: Received manual retry request for ConnectId {ConnectId}", evt.ConnectId);
        
        try
        {
            // First: Clear all exhausted operations to allow fresh retry
            ClearExhaustedOperations();
            
            // Second: Attempt to retry operations (they should now proceed without exhaustion blocks)
            bool anySucceeded = await RetryAllExhaustedOperationsAsync();
            
            if (anySucceeded)
            {
                Log.Information("ðŸ”„ MANUAL RETRY: Operations succeeded. Connection restored");
                _uiDispatcher.Post(() =>
                {
                    try
                    {
                        _networkEvents.InitiateChangeState(
                            NetworkStatusChangedEvent.New(NetworkStatus.ConnectionRestored));
                    }
                    catch (Exception ex)
                    {
                        Log.Error(ex, "Failed to notify UI of connection restored state");
                    }
                });
            }
            else
            {
                Log.Information("ðŸ”„ MANUAL RETRY: Operations failed. Will retry via normal retry strategy");
                // Don't immediately show retry button - let normal retry strategy handle exhaustion
            }
        }
        catch (Exception ex)
        {
            Log.Error(ex, "ðŸš¨ MANUAL RETRY ERROR: Failed to handle manual retry request");
        }
    }

    private async Task<bool> RetryAllExhaustedOperationsAsync()
    {
        await _stateLock.WaitAsync();
        List<RetryOperationInfo> exhaustedOperations;
        try
        {
            exhaustedOperations = _activeRetryOperations.Values
                .Where(op => op.IsExhausted && op.Operation != null)
                .ToList();
        }
        finally
        {
            _stateLock.Release();
        }

        if (exhaustedOperations.Count == 0)
        {
            Log.Debug("ðŸ”„ MANUAL RETRY: No exhausted operations to retry");
            return false;
        }

        Log.Information("ðŸ”„ MANUAL RETRY: Retrying {Count} exhausted operations", exhaustedOperations.Count);

        bool anySucceeded = false;
        foreach (RetryOperationInfo operation in exhaustedOperations)
        {
            try
            {
                operation.IsExhausted = false;
                operation.CurrentRetryCount = 0;
                
                Result<object, NetworkFailure> result = await operation.Operation!();
                if (result.IsOk)
                {
                    StopTrackingOperation(operation.UniqueKey, "Manual retry succeeded");
                    anySucceeded = true;
                    Log.Information("ðŸ”„ MANUAL RETRY SUCCESS: Operation {OperationName} succeeded and cleaned up", operation.OperationName);
                }
                else
                {
                    operation.IsExhausted = true;
                    Log.Debug("ðŸ”„ MANUAL RETRY: Operation {OperationName} failed again during manual retry", operation.OperationName);
                }
            }
            catch (Exception ex)
            {
                operation.IsExhausted = true;
                Log.Error(ex, "ðŸ”„ MANUAL RETRY: Error retrying operation {OperationName}", operation.OperationName);
            }
        }

        Log.Information("ðŸ”„ MANUAL RETRY: Completed. Any succeeded: {AnySucceeded}", anySucceeded);
        return anySucceeded;
    }

    private void StartTrackingOperation(string operationName, uint connectId, int maxRetries, string operationKey, Func<Task<Result<object, NetworkFailure>>>? operation = null)
    {
        // Prevent memory leaks by enforcing operation limit
        if (_activeRetryOperations.Count >= MAX_TRACKED_OPERATIONS)
        {
            Log.Warning("Maximum tracked operations limit reached ({MaxOperations}), cleaning up old operations", MAX_TRACKED_OPERATIONS);
            CleanupAbandonedOperations(null);
        }

        var operationInfo = new RetryOperationInfo
        {
            OperationName = operationName,
            ConnectId = connectId,
            StartTime = DateTime.UtcNow,
            MaxRetries = maxRetries,
            UniqueKey = operationKey,
            Operation = operation
        };

        operationInfo.CurrentRetryCount = 1;
        operationInfo.IsExhausted = false;

        _activeRetryOperations.TryAdd(operationKey, operationInfo);
        Log.Debug("ðŸŸ¡ STARTED TRACKING: Operation {OperationName} on ConnectId {ConnectId} - Key: {OperationKey}. Active operations: {ActiveCount}", 
            operationName, connectId, operationKey, _activeRetryOperations.Count);
    }

    private void UpdateOperationRetryCount(string operationKey, int retryCount)
    {
        if (_activeRetryOperations.TryGetValue(operationKey, out RetryOperationInfo? operation))
        {
            operation.CurrentRetryCount = retryCount;
            Log.Debug("ðŸ“Š UPDATED TRACKING: Key {OperationKey} - Retry count: {RetryCount}/{MaxRetries}", 
                operationKey, retryCount, operation.MaxRetries);
        }
    }

    private void StopTrackingOperation(string operationKey, string reason)
    {
        if (_activeRetryOperations.TryRemove(operationKey, out RetryOperationInfo? operation))
        {
            Log.Debug("ðŸŸ¢ STOPPED TRACKING: Operation {OperationName} on ConnectId {ConnectId} - Reason: {Reason}. Remaining active operations: {ActiveCount}",
                operation.OperationName, operation.ConnectId, reason, _activeRetryOperations.Count);
        }
    }

    private void MarkOperationAsExhausted(string operationKey)
    {
        if (_activeRetryOperations.TryGetValue(operationKey, out RetryOperationInfo? operation))
        {
            operation.IsExhausted = true;
            Log.Debug("ðŸ”´ MARKED AS EXHAUSTED: Operation {OperationName} on ConnectId {ConnectId} - Key: {OperationKey}",
                operation.OperationName, operation.ConnectId, operationKey);
        }
    }

    private void CleanupAbandonedOperations(object? state)
    {
        if (_isDisposed)
            return;

        try
        {
            var cutoff = DateTime.UtcNow.AddMinutes(-OPERATION_TIMEOUT_MINUTES);
            var abandonedKeys = _activeRetryOperations.Values
                .Where(op => op.StartTime < cutoff)
                .Select(op => op.UniqueKey)
                .ToList();

            foreach (string key in abandonedKeys)
            {
                if (_activeRetryOperations.TryRemove(key, out var operation))
                {
                    Log.Debug("ðŸ§¹ CLEANUP: Removed abandoned operation {OperationName} after {Minutes} minutes", 
                        operation.OperationName, OPERATION_TIMEOUT_MINUTES);
                }
            }

            if (abandonedKeys.Any())
            {
                Log.Information("ðŸ§¹ CLEANUP: Removed {Count} abandoned operations from tracking", abandonedKeys.Count);
            }
        }
        catch (Exception ex)
        {
            Log.Error(ex, "Error during operation cleanup");
        }
    }

    #endregion

    #region Private Methods - AOT-Compatible Retry Policies

    private AsyncPolicyWrap<Result<TResponse, NetworkFailure>> CreateTypedRetryPolicy<TResponse>(
        int maxRetries, 
        string operationKey, 
        string operationName, 
        uint connectId)
    {
        // Create retry delays
        IEnumerable<TimeSpan> rawDelays = _configuration.UseAdaptiveRetry 
            ? Backoff.DecorrelatedJitterBackoffV2(
                medianFirstRetryDelay: _configuration.InitialRetryDelay,
                retryCount: maxRetries,
                fastFirst: true)
            : Backoff.ExponentialBackoff(
                initialDelay: _configuration.InitialRetryDelay,
                retryCount: maxRetries,
                factor: 2.0,
                fastFirst: true);
        
        TimeSpan[] retryDelays = rawDelays.Select(delay => 
            delay > _configuration.MaxRetryDelay ? _configuration.MaxRetryDelay : delay).ToArray();

        // Create AOT-compatible delegates
        var shouldRetryDelegate = RetryDecisionFactory.CreateShouldRetryDelegate<TResponse>();
        var connectionRecoveryDelegate = RetryDecisionFactory.CreateConnectionRecoveryDelegate<TResponse>();

        // Create typed retry policy
        IAsyncPolicy<Result<TResponse, NetworkFailure>> retryPolicy = Policy
            .HandleResult<Result<TResponse, NetworkFailure>>(result => shouldRetryDelegate(result))
            .WaitAndRetryAsync(
                retryDelays,
                onRetry: (outcome, delay, retryCount, context) =>
                {
                    Log.Information("ðŸ”„ RETRY ATTEMPT: Operation {OperationName} on ConnectId {ConnectId} - Attempt {RetryCount}/{MaxRetries}, delay: {DelayMs}ms", 
                        operationName, connectId, retryCount, retryDelays.Length, delay.TotalMilliseconds);

                    if (retryCount == 1)
                    {
                        StartTrackingOperation(operationName, connectId, retryDelays.Length, operationKey);
                    }
                    else
                    {
                        UpdateOperationRetryCount(operationKey, retryCount);
                    }

                    if (retryCount >= retryDelays.Length)
                    {
                        Log.Warning("ðŸ”´ RETRY DELAYS EXHAUSTED: Operation {OperationName} on ConnectId {ConnectId} - Attempt {RetryCount}/{MaxRetries} exhausted all retries", 
                            operationName, connectId, retryCount, retryDelays.Length);
                        
                        MarkOperationAsExhausted(operationKey);
                        
                        // Check if this triggers global exhaustion
                        bool allExhausted = IsGloballyExhausted();
                        if (allExhausted)
                        {
                            Log.Warning("ðŸ”´ ALL OPERATIONS EXHAUSTED: All retry operations are exhausted. Recovery will handle retry button display");
                            
                            _uiDispatcher.Post(() =>
                            {
                                try
                                {
                                    _networkEvents.InitiateChangeState(
                                        NetworkStatusChangedEvent.New(NetworkStatus.RetriesExhausted));
                                }
                                catch (Exception ex)
                                {
                                    Log.Error(ex, "Failed to notify UI of exhausted state");
                                }
                            });
                        }
                        else
                        {
                            // Check if this is the first exhausted operation
                            var exhaustedCount = _activeRetryOperations.Values.Count(op => op.IsExhausted);
                            if (exhaustedCount == 1)
                            {
                                Log.Information("ðŸ”´ FIRST OPERATION EXHAUSTED: Showing notification window without retry button");
                                
                                _uiDispatcher.Post(() =>
                                {
                                    try
                                    {
                                        _networkEvents.InitiateChangeState(
                                            NetworkStatusChangedEvent.New(NetworkStatus.DataCenterDisconnected));
                                    }
                                    catch (Exception ex)
                                    {
                                        Log.Error(ex, "Failed to notify UI of disconnected state");
                                    }
                                });
                            }
                            
                            Log.Debug("â³ OTHER OPERATIONS STILL RETRYING: Not showing retry button yet. Exhausted operations: {ExhaustedCount}", exhaustedCount);
                        }
                    }

                    // Handle connection recovery if needed
                    if (connectionRecoveryDelegate(outcome.Result))
                    {
                        _ = Task.Run(() => EnsureSecrecyChannelAsync(connectId));
                    }
                });

        // Note: Circuit breaker disabled for individual operations to prevent
        // interference with retry policy. Circuit breaking should be handled
        // at a higher level (e.g., per-service or per-endpoint basis)

        // Create timeout policy
        IAsyncPolicy timeoutPolicy = Policy.TimeoutAsync(
            TimeSpan.FromSeconds(30), 
            onTimeoutAsync: (_, timespan, _) =>
            {
                Log.Warning("Operation {OperationName} timed out after {Timeout}", operationName, timespan);
                return Task.CompletedTask;
            });

        // For network operations, we want timeouts on individual attempts,
        // retries for transient failures, but circuit breaker should be disabled
        // during the retry process to avoid premature blocking
        return retryPolicy
            .WrapAsync(timeoutPolicy);
    }

    private async Task EnsureSecrecyChannelAsync(uint connectId)
    {
        NetworkProvider? networkProvider = GetNetworkProvider();
        if (networkProvider == null)
        {
            Log.Debug("NetworkProvider not available for connection recovery");
            return;
        }

        try
        {
            if (networkProvider.IsConnectionHealthy(connectId))
            {
                return;
            }

            Log.Debug("Attempting to restore connection for ConnectId {ConnectId}", connectId);
            Result<bool, NetworkFailure> restoreResult = await networkProvider.TryRestoreConnectionAsync(connectId).ConfigureAwait(false);
            
            if (restoreResult.IsOk && restoreResult.Unwrap())
            {
                Log.Information("Successfully restored connection for ConnectId {ConnectId}", connectId);
            }
            else if (restoreResult.IsErr)
            {
                Log.Warning("Failed to restore connection for ConnectId {ConnectId}: {Error}", connectId, restoreResult.UnwrapErr().Message);
            }
        }
        catch (Exception ex)
        {
            Log.Warning(ex, "Error attempting to restore connection for ConnectId {ConnectId}", connectId);
        }
    }

    #endregion

    #region Private Utility Methods

    private NetworkProvider? GetNetworkProvider()
    {
        try
        {
            return _lazyNetworkProvider?.Value;
        }
        catch (Exception ex)
        {
            Log.Warning(ex, "Failed to get NetworkProvider instance");
            return null;
        }
    }

    private static string CreateOperationKey(string operationName, uint connectId, DateTime startTime)
    {
        return $"{operationName}_{connectId}_{startTime.Ticks}";
    }

    #endregion
}